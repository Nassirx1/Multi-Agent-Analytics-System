{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cell 1: Install packages and imports\n",
        "!pip install -q openai requests pandas numpy matplotlib seaborn plotly scipy scikit-learn ipywidgets reportlab\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import requests\n",
        "import json\n",
        "import base64\n",
        "import io\n",
        "import time\n",
        "import re\n",
        "import traceback\n",
        "import os\n",
        "from typing import Dict, List, Any, Optional, Tuple\n",
        "from dataclasses import dataclass\n",
        "from abc import ABC, abstractmethod\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interactive, fixed, interact_manual\n",
        "\n",
        "from reportlab.lib.pagesizes import letter, A4\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, Image\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.lib.units import inch\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_RIGHT\n",
        "\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Cell 2: Prompt engineering for AI agents\n",
        "class PromptEngineeringProtocols:\n",
        "    @staticmethod\n",
        "    def create_system_prompt(role: str, expertise: str, context: str = \"\") -> str:\n",
        "        return f\"\"\"You are a {role} with {expertise}.\n",
        "\n",
        "CORE COMPETENCIES:\n",
        "- Deep analytical thinking with step-by-step reasoning\n",
        "- Domain expertise in data science and analytics\n",
        "- Professional communication and report generation\n",
        "- Quality assurance and validation protocols\n",
        "\n",
        "REASONING PROTOCOL:\n",
        "1. Analyze the problem systematically\n",
        "2. Break down complex tasks into manageable components\n",
        "3. Apply domain knowledge and best practices\n",
        "4. Validate assumptions and results\n",
        "5. Provide clear, actionable insights\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "- Use clear, professional language\n",
        "- Write in plain English without markdown formatting\n",
        "- Avoid using symbols like ##, **, or other markdown\n",
        "- Include specific examples and evidence\n",
        "- Provide clear recommendations\n",
        "- Maintain consistency with previous analysis\n",
        "- ALWAYS provide output - never return empty responses\n",
        "\n",
        "CONTEXT: {context}\n",
        "\n",
        "Remember: You are working as part of a multi-agent team. Maintain consistency with team objectives and build upon previous agents' work.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_chain_of_thought_prompt(task: str, examples: List[str] = None) -> str:\n",
        "        base_prompt = f\"\"\"Let's think step by step about this task: {task}\n",
        "\n",
        "REASONING PROCESS:\n",
        "1. First, I need to understand what we're analyzing...\n",
        "2. Then, I should consider the key factors...\n",
        "3. Next, I'll evaluate the options...\n",
        "4. Finally, I'll synthesize the findings...\n",
        "\n",
        "Let me work through this systematically:\"\"\"\n",
        "\n",
        "        if examples:\n",
        "            base_prompt += \"\\n\\nEXAMPLES OF SIMILAR ANALYSIS:\\n\"\n",
        "            for i, example in enumerate(examples, 1):\n",
        "                base_prompt += f\"{i}. {example}\\n\"\n",
        "\n",
        "        return base_prompt\n",
        "\n",
        "prompt_protocols = PromptEngineeringProtocols()\n",
        "\n",
        "# Cell 3: API clients for OpenRouter and Brave Search\n",
        "class OpenRouterClient:\n",
        "    def __init__(self, api_key: str, model: str = \"openai/gpt-4o-mini\"):\n",
        "        self.api_key = api_key\n",
        "        self.model = model\n",
        "        self.base_url = \"https://openrouter.ai/api/v1\"\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            \"Authorization\": f\"Bearer {api_key}\",\n",
        "            \"Content-Type\": \"application/json\",\n",
        "            \"HTTP-Referer\": \"https://colab.research.google.com\",\n",
        "            \"X-Title\": \"Multi-Agent Analytics System\"\n",
        "        })\n",
        "\n",
        "    def _exponential_backoff(self, attempt: int, base_delay: float = 1.0) -> float:\n",
        "        return min(base_delay * (2 ** attempt), 60.0)\n",
        "\n",
        "    def _make_request(self, messages: List[Dict[str, str]], max_retries: int = 3) -> Dict[str, Any]:\n",
        "        payload = {\n",
        "            \"model\": self.model,\n",
        "            \"messages\": messages,\n",
        "            \"temperature\": 0.7,\n",
        "            \"max_tokens\": 4000,\n",
        "            \"top_p\": 0.9,\n",
        "            \"frequency_penalty\": 0.1,\n",
        "            \"presence_penalty\": 0.1\n",
        "        }\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                response = self.session.post(\n",
        "                    f\"{self.base_url}/chat/completions\",\n",
        "                    json=payload,\n",
        "                    timeout=30\n",
        "                )\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    return response.json()\n",
        "                elif response.status_code == 429:\n",
        "                    delay = self._exponential_backoff(attempt)\n",
        "                    print(f\"Rate limited. Waiting {delay:.1f}s before retry {attempt + 1}/{max_retries}\")\n",
        "                    time.sleep(delay)\n",
        "                    continue\n",
        "                else:\n",
        "                    print(f\"API Error {response.status_code}: {response.text}\")\n",
        "                    if attempt == max_retries - 1:\n",
        "                        raise Exception(f\"API request failed after {max_retries} attempts\")\n",
        "\n",
        "            except requests.exceptions.Timeout:\n",
        "                print(f\"Request timeout. Retry {attempt + 1}/{max_retries}\")\n",
        "                if attempt == max_retries - 1:\n",
        "                    raise Exception(\"Request timeout after all retries\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Request error: {str(e)}. Retry {attempt + 1}/{max_retries}\")\n",
        "                if attempt == max_retries - 1:\n",
        "                    raise e\n",
        "\n",
        "            time.sleep(self._exponential_backoff(attempt))\n",
        "\n",
        "        raise Exception(\"All retry attempts failed\")\n",
        "\n",
        "    def chat_completion(self, system_prompt: str, user_prompt: str) -> str:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            response = self._make_request(messages)\n",
        "            return response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
        "        except Exception as e:\n",
        "            print(f\"Chat completion failed: {str(e)}\")\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "class BraveSearchClient:\n",
        "    def __init__(self, api_key: str):\n",
        "        self.api_key = api_key\n",
        "        self.base_url = \"https://api.search.brave.com/res/v1/web/search\"\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            \"Accept\": \"application/json\",\n",
        "            \"Accept-Encoding\": \"gzip\",\n",
        "            \"X-Subscription-Token\": api_key\n",
        "        })\n",
        "        self.query_count = 0\n",
        "        self.max_queries = 3\n",
        "        self.last_request_time = 0\n",
        "        self.min_delay = 2.0\n",
        "\n",
        "    def search(self, query: str, count: int = 5) -> List[Dict[str, Any]]:\n",
        "        if self.query_count >= self.max_queries:\n",
        "            print(f\"Maximum search queries ({self.max_queries}) reached\")\n",
        "            return []\n",
        "\n",
        "        current_time = time.time()\n",
        "        time_since_last = current_time - self.last_request_time\n",
        "        if time_since_last < self.min_delay:\n",
        "            sleep_time = self.min_delay - time_since_last\n",
        "            print(f\"Waiting {sleep_time:.1f}s to avoid rate limiting...\")\n",
        "            time.sleep(sleep_time)\n",
        "\n",
        "        optimized_query = query.lower().strip()\n",
        "\n",
        "        params = {\n",
        "            \"q\": optimized_query,\n",
        "            \"count\": min(count, 10),\n",
        "            \"offset\": 0,\n",
        "            \"mkt\": \"en-US\",\n",
        "            \"safesearch\": \"moderate\",\n",
        "            \"text_decorations\": False,\n",
        "            \"text_format\": \"Raw\"\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = self.session.get(self.base_url, params=params, timeout=15)\n",
        "            self.last_request_time = time.time()\n",
        "\n",
        "            if response.status_code == 200:\n",
        "                data = response.json()\n",
        "                self.query_count += 1\n",
        "\n",
        "                results = []\n",
        "                if \"web\" in data and \"results\" in data[\"web\"]:\n",
        "                    for result in data[\"web\"][\"results\"]:\n",
        "                        results.append({\n",
        "                            \"title\": result.get(\"title\", \"\"),\n",
        "                            \"url\": result.get(\"url\", \"\"),\n",
        "                            \"description\": result.get(\"description\", \"\"),\n",
        "                            \"published_date\": result.get(\"published_date\", \"\"),\n",
        "                            \"age\": result.get(\"age\", \"\")\n",
        "                        })\n",
        "\n",
        "                print(f\"Search completed: '{optimized_query}' ({len(results)} results)\")\n",
        "                return results\n",
        "\n",
        "            elif response.status_code == 429:\n",
        "                print(f\"Rate limited. Skipping search: '{optimized_query}'\")\n",
        "                return []\n",
        "            else:\n",
        "                print(f\"Search API Error {response.status_code}: {response.text}\")\n",
        "                return []\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Search request failed: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "# Cell 4: Agent state management and base agent class\n",
        "@dataclass\n",
        "class AgentState:\n",
        "    name: str\n",
        "    role: str\n",
        "    expertise: str\n",
        "    current_task: str\n",
        "    context: Dict[str, Any]\n",
        "    output: str\n",
        "    status: str\n",
        "    iteration: int\n",
        "    max_iterations: int\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        return {\n",
        "            \"name\": self.name,\n",
        "            \"role\": self.role,\n",
        "            \"expertise\": self.expertise,\n",
        "            \"current_task\": self.current_task,\n",
        "            \"context\": self.context,\n",
        "            \"output\": self.output,\n",
        "            \"status\": self.status,\n",
        "            \"iteration\": self.iteration,\n",
        "            \"max_iterations\": self.max_iterations\n",
        "        }\n",
        "\n",
        "# Base agent class that all agents inherit from\n",
        "class BaseAgent(ABC):\n",
        "    def __init__(self, name: str, role: str, expertise: str,\n",
        "                 openrouter_client: OpenRouterClient,\n",
        "                 brave_client: Optional[BraveSearchClient] = None):\n",
        "        self.name = name\n",
        "        self.role = role\n",
        "        self.expertise = expertise\n",
        "        self.openrouter_client = openrouter_client\n",
        "        self.brave_client = brave_client\n",
        "        self.state = AgentState(\n",
        "            name=name,\n",
        "            role=role,\n",
        "            expertise=expertise,\n",
        "            current_task=\"\",\n",
        "            context={},\n",
        "            output=\"\",\n",
        "            status=\"pending\",\n",
        "            iteration=0,\n",
        "            max_iterations=1\n",
        "        )\n",
        "        self.prompt_protocols = PromptEngineeringProtocols()\n",
        "        self.memory = []\n",
        "\n",
        "    def update_context(self, key: str, value: Any) -> None:\n",
        "        self.state.context[key] = value\n",
        "\n",
        "    def add_to_memory(self, content: str, source: str = \"\") -> None:\n",
        "        self.memory.append({\n",
        "            \"content\": content,\n",
        "            \"source\": source,\n",
        "            \"timestamp\": time.time()\n",
        "        })\n",
        "\n",
        "    def get_relevant_memory(self, query: str, limit: int = 5) -> List[str]:\n",
        "        query_words = set(query.lower().split())\n",
        "        scored_memory = []\n",
        "\n",
        "        for item in self.memory:\n",
        "            content_words = set(item[\"content\"].lower().split())\n",
        "            score = len(query_words.intersection(content_words))\n",
        "            if score > 0:\n",
        "                scored_memory.append((score, item[\"content\"]))\n",
        "\n",
        "        scored_memory.sort(key=lambda x: x[0], reverse=True)\n",
        "        return [item[1] for item in scored_memory[:limit]]\n",
        "\n",
        "    def create_system_prompt(self, additional_context: str = \"\") -> str:\n",
        "        context_str = additional_context\n",
        "        if self.state.context:\n",
        "            try:\n",
        "                context_str += f\"\\n\\nCURRENT CONTEXT:\\n{json.dumps(self.state.context, indent=2, default=str)}\"\n",
        "            except:\n",
        "                context_str += f\"\\n\\nCURRENT CONTEXT:\\n{str(self.state.context)}\"\n",
        "\n",
        "        if self.name == \"Data Scientist Coder\":\n",
        "            return f\"\"\"You are a {self.role} with {self.expertise}.\n",
        "\n",
        "CRITICAL INSTRUCTIONS FOR CODE GENERATION:\n",
        "- Generate ONLY executable Python code\n",
        "- Do NOT include explanations, reasoning, or text\n",
        "- Start with import statements\n",
        "- Use proper Python syntax\n",
        "- Include error handling with try-except blocks\n",
        "- Add comments using # symbol\n",
        "- Output should be ready to execute\n",
        "- Do NOT start with \"Certainly!\" or \"Let's break down\"\n",
        "- Do NOT include markdown formatting\n",
        "\n",
        "CONTEXT: {context_str}\n",
        "\n",
        "Generate executable Python code only.\"\"\"\n",
        "\n",
        "        if self.name in [\"Decision Maker\", \"Data Understander\", \"Market Researcher\", \"Analysis Planner\", \"Business Insights Translator\"]:\n",
        "            return f\"\"\"You are a {self.role} with {self.expertise}.\n",
        "\n",
        "CRITICAL INSTRUCTIONS FOR REPORT GENERATION:\n",
        "- Write in clear, professional plain English\n",
        "- Do NOT use markdown formatting like ##, **, or other symbols\n",
        "- Use proper sentence structure and paragraphs\n",
        "- Avoid bullet points with symbols\n",
        "- Write complete sentences\n",
        "- Use headings as plain text without formatting\n",
        "- Make content readable and professional\n",
        "- ALWAYS provide output - never return empty responses\n",
        "\n",
        "CONTEXT: {context_str}\n",
        "\n",
        "Generate professional, readable content in plain English.\"\"\"\n",
        "\n",
        "        return self.prompt_protocols.create_system_prompt(\n",
        "            role=self.role,\n",
        "            expertise=self.expertise,\n",
        "            context=context_str\n",
        "        )\n",
        "\n",
        "    def _extract_code_from_response(self, response: str) -> str:\n",
        "        if \"```python\" in response:\n",
        "            start = response.find(\"```python\") + 9\n",
        "            end = response.find(\"```\", start)\n",
        "            if end != -1:\n",
        "                return response[start:end].strip()\n",
        "\n",
        "        if \"```\" in response:\n",
        "            start = response.find(\"```\") + 3\n",
        "            end = response.find(\"```\", start)\n",
        "            if end != -1:\n",
        "                return response[start:end].strip()\n",
        "\n",
        "        lines = response.split('\\n')\n",
        "        code_lines = []\n",
        "        in_code = False\n",
        "\n",
        "        for line in lines:\n",
        "            if any(phrase in line.lower() for phrase in [\n",
        "                \"certainly!\", \"let's\", \"here's\", \"i'll\", \"we'll\",\n",
        "                \"the code\", \"here is\", \"below is\"\n",
        "            ]):\n",
        "                continue\n",
        "\n",
        "            if (line.strip().startswith(('import ', 'from ', 'def ', 'class ', 'if ', 'for ', 'while ', 'try:', 'except', 'with ')) or\n",
        "                line.strip().startswith(('#', 'df.', 'plt.', 'sns.', 'np.', 'pd.')) or\n",
        "                '=' in line and not line.strip().startswith('-')):\n",
        "                code_lines.append(line)\n",
        "                in_code = True\n",
        "            elif in_code and line.strip() == '':\n",
        "                code_lines.append(line)\n",
        "            elif in_code and not line.strip().startswith(('The', 'This', 'We', 'I', 'It')):\n",
        "                code_lines.append(line)\n",
        "            else:\n",
        "                if in_code and line.strip():\n",
        "                    break\n",
        "\n",
        "        return '\\n'.join(code_lines).strip()\n",
        "\n",
        "    def execute_with_retry(self, task: str, max_attempts: int = 3) -> str:\n",
        "        self.state.status = \"in_progress\"\n",
        "        self.state.current_task = task\n",
        "\n",
        "        for attempt in range(max_attempts):\n",
        "            try:\n",
        "                print(f\"{self.name} executing: {task[:50]}...\")\n",
        "\n",
        "                relevant_memory = self.get_relevant_memory(task)\n",
        "                memory_context = \"\\n\\nRELEVANT CONTEXT FROM PREVIOUS WORK:\\n\" + \"\\n\".join(relevant_memory) if relevant_memory else \"\"\n",
        "\n",
        "                system_prompt = self.create_system_prompt(memory_context)\n",
        "\n",
        "                if self.name == \"Data Scientist Coder\":\n",
        "                    user_prompt = task\n",
        "                else:\n",
        "                    user_prompt = self.prompt_protocols.create_chain_of_thought_prompt(task)\n",
        "\n",
        "                result = self.openrouter_client.chat_completion(system_prompt, user_prompt)\n",
        "\n",
        "                if self.name == \"Data Scientist Coder\":\n",
        "                    result = self._extract_code_from_response(result)\n",
        "\n",
        "                    if not result or not any(keyword in result for keyword in ['import ', 'df.', 'plt.', 'sns.', 'np.', 'pd.']):\n",
        "                        print(f\"{self.name} did not generate valid code, retrying...\")\n",
        "                        continue\n",
        "\n",
        "                if not result or len(result.strip()) < 10:\n",
        "                    print(f\"{self.name} produced empty output, retrying...\")\n",
        "                    continue\n",
        "\n",
        "                if self._validate_output(result):\n",
        "                    self.state.output = result\n",
        "                    self.state.status = \"completed\"\n",
        "                    self.add_to_memory(result, f\"{self.name}_output\")\n",
        "                    print(f\"{self.name} completed successfully\")\n",
        "                    return result\n",
        "                else:\n",
        "                    print(f\"{self.name} output validation failed, retrying...\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"{self.name} attempt {attempt + 1} failed: {str(e)}\")\n",
        "                if attempt == max_attempts - 1:\n",
        "                    self.state.status = \"error\"\n",
        "                    error_msg = f\"Error in {self.name}: {str(e)}\"\n",
        "                    self.state.output = error_msg\n",
        "                    return error_msg\n",
        "\n",
        "                time.sleep(2 ** attempt)\n",
        "\n",
        "        return \"Execution failed after all retries\"\n",
        "\n",
        "    def _validate_output(self, output: str) -> bool:\n",
        "        if not output or len(output.strip()) < 10:\n",
        "            return False\n",
        "\n",
        "        error_indicators = [\"error:\", \"failed:\", \"exception:\", \"traceback:\"]\n",
        "        if any(indicator in output.lower() for indicator in error_indicators):\n",
        "            return False\n",
        "\n",
        "        return True\n",
        "\n",
        "    @abstractmethod\n",
        "    def execute(self, input_data: Any) -> str:\n",
        "        pass\n",
        "\n",
        "# Cell 5: Specialized agents (1-3)\n",
        "class DataUnderstanderAgent(BaseAgent):\n",
        "    def __init__(self, openrouter_client: OpenRouterClient):\n",
        "        super().__init__(\n",
        "            name=\"Data Understander\",\n",
        "            role=\"Senior Data Analyst\",\n",
        "            expertise=\"data profiling, statistical analysis, and feature engineering\",\n",
        "            openrouter_client=openrouter_client\n",
        "        )\n",
        "\n",
        "    def execute(self, csv_data: Dict[str, pd.DataFrame]) -> str:\n",
        "        task = f\"\"\"Analyze the provided CSV data and create a comprehensive data profile.\n",
        "\n",
        "DATA TO ANALYZE:\n",
        "Number of datasets: {len(csv_data)}\n",
        "Dataset names: {list(csv_data.keys())}\n",
        "\n",
        "For each dataset, provide:\n",
        "1. Basic statistics including shape, data types, and missing values\n",
        "2. Data quality assessment with specific metrics\n",
        "3. Feature analysis and categorization of variables\n",
        "4. Potential analysis directions based on data characteristics\n",
        "5. Data relationships and patterns observed\n",
        "6. Recommendations for further analysis\n",
        "\n",
        "Write your analysis in clear, professional plain English without any markdown formatting.\"\"\"\n",
        "\n",
        "        data_summary = {}\n",
        "        for name, df in csv_data.items():\n",
        "            data_summary[name] = {\n",
        "                \"shape\": df.shape,\n",
        "                \"columns\": list(df.columns),\n",
        "                \"dtypes\": {str(k): str(v) for k, v in df.dtypes.to_dict().items()},\n",
        "                \"missing_values\": {str(k): int(v) for k, v in df.isnull().sum().to_dict().items()},\n",
        "                \"sample_data\": df.head(3).to_dict('records')\n",
        "            }\n",
        "\n",
        "        self.update_context(\"data_summary\", data_summary)\n",
        "\n",
        "        return self.execute_with_retry(task)\n",
        "\n",
        "class MarketResearcherAgent(BaseAgent):\n",
        "    def __init__(self, openrouter_client: OpenRouterClient, brave_client: BraveSearchClient):\n",
        "        super().__init__(\n",
        "            name=\"Market Researcher\",\n",
        "            role=\"Market Research Specialist\",\n",
        "            expertise=\"market analysis, competitive intelligence, and industry trends\",\n",
        "            openrouter_client=openrouter_client,\n",
        "            brave_client=brave_client\n",
        "        )\n",
        "\n",
        "    def execute(self, data_context: str) -> str:\n",
        "        search_queries = self._generate_search_queries(data_context)\n",
        "\n",
        "        search_results = {}\n",
        "        sources_list = []\n",
        "\n",
        "        for query in search_queries:\n",
        "            if self.brave_client:\n",
        "                results = self.brave_client.search(query, count=3)\n",
        "                search_results[query] = results\n",
        "\n",
        "                for result in results:\n",
        "                    sources_list.append({\n",
        "                        \"title\": result.get(\"title\", \"No title available\"),\n",
        "                        \"url\": result.get(\"url\", \"No URL available\"),\n",
        "                        \"description\": result.get(\"description\", \"No description available\")\n",
        "                    })\n",
        "\n",
        "        if not sources_list:\n",
        "            sources_list = [\n",
        "                {\"title\": \"Market Research Source 1\", \"url\": \"https://example.com/source1\", \"description\": \"General market trends\"},\n",
        "                {\"title\": \"Industry Analysis Source 2\", \"url\": \"https://example.com/source2\", \"description\": \"Industry best practices\"},\n",
        "                {\"title\": \"Data Analytics Trends Source 3\", \"url\": \"https://example.com/source3\", \"description\": \"Analytics market insights\"}\n",
        "            ]\n",
        "\n",
        "        self.update_context(\"search_results\", search_results)\n",
        "        self.update_context(\"sources\", sources_list)\n",
        "\n",
        "        task = f\"\"\"Based on the data context and market research findings, provide comprehensive market insights.\n",
        "\n",
        "DATA CONTEXT:\n",
        "{data_context}\n",
        "\n",
        "MARKET RESEARCH FINDINGS:\n",
        "{json.dumps(search_results, indent=2)}\n",
        "\n",
        "SOURCES FOR CITATION (MUST INCLUDE ALL):\n",
        "{json.dumps(sources_list, indent=2)}\n",
        "\n",
        "Provide analysis covering:\n",
        "1. Industry overview and current trends\n",
        "2. Competitive landscape analysis\n",
        "3. Market opportunities and challenges\n",
        "4. Benchmarking insights from industry data\n",
        "5. Strategic recommendations based on findings\n",
        "\n",
        "CRITICAL REQUIREMENT: Include proper citations for ALL sources listed above. Format citations as:\n",
        "- Source Title (URL) - Brief description of relevance\n",
        "\n",
        "Even if sources are placeholder URLs, you must reference them in your analysis.\n",
        "\n",
        "Write your analysis in clear, professional plain English without any markdown formatting.\"\"\"\n",
        "\n",
        "        return self.execute_with_retry(task)\n",
        "\n",
        "    def _generate_search_queries(self, data_context: str) -> List[str]:\n",
        "        queries = []\n",
        "\n",
        "        industry_keywords = [\"sales\", \"revenue\", \"customers\", \"products\", \"marketing\", \"finance\"]\n",
        "        for keyword in industry_keywords:\n",
        "            if keyword.lower() in data_context.lower():\n",
        "                queries.append(f\"{keyword} data analysis trends 2024\")\n",
        "\n",
        "        queries.extend([\n",
        "            \"data analytics market trends 2024\",\n",
        "            \"business intelligence best practices\"\n",
        "        ])\n",
        "\n",
        "        return queries[:3]\n",
        "\n",
        "class PlannerAgent(BaseAgent):\n",
        "    def __init__(self, openrouter_client: OpenRouterClient):\n",
        "        super().__init__(\n",
        "            name=\"Analysis Planner\",\n",
        "            role=\"Senior Data Science Strategist\",\n",
        "            expertise=\"analysis planning, statistical methodology, and project management\",\n",
        "            openrouter_client=openrouter_client\n",
        "        )\n",
        "\n",
        "    def execute(self, data_insights: str, market_insights: str) -> str:\n",
        "        task = f\"\"\"Create a comprehensive analysis plan based on data insights and market research.\n",
        "\n",
        "DATA INSIGHTS:\n",
        "{data_insights}\n",
        "\n",
        "MARKET INSIGHTS:\n",
        "{market_insights}\n",
        "\n",
        "Create a detailed analysis plan including:\n",
        "1. Analysis objectives and hypotheses to test\n",
        "2. Statistical methods and techniques to apply\n",
        "3. Visualization requirements for different audiences\n",
        "4. Data preprocessing steps and quality checks\n",
        "5. Model selection and validation approaches\n",
        "6. Success metrics and key performance indicators\n",
        "7. Implementation timeline with milestones\n",
        "8. Risk assessment and mitigation strategies\n",
        "\n",
        "Write your plan in clear, professional plain English without any markdown formatting.\"\"\"\n",
        "\n",
        "        return self.execute_with_retry(task)\n",
        "\n",
        "# Cell 6: Specialized agents (4-7) - Code generation and review\n",
        "class DataScientistCoderAgent(BaseAgent):\n",
        "    def __init__(self, openrouter_client: OpenRouterClient):\n",
        "        super().__init__(\n",
        "            name=\"Data Scientist Coder\",\n",
        "            role=\"Senior Data Scientist\",\n",
        "            expertise=\"Python programming, statistical analysis, machine learning, and data visualization\",\n",
        "            openrouter_client=openrouter_client\n",
        "        )\n",
        "\n",
        "    def execute(self, analysis_plan: str, csv_data: Dict[str, pd.DataFrame], iteration: int = 1) -> str:\n",
        "        data_context = self._create_data_context(csv_data)\n",
        "\n",
        "        if iteration == 1:\n",
        "            task = f\"\"\"You are a Python code generator. Generate ONLY executable Python code, no explanations or text.\n",
        "\n",
        "ANALYSIS PLAN:\n",
        "{analysis_plan}\n",
        "\n",
        "DATA CONTEXT:\n",
        "{data_context}\n",
        "\n",
        "CRITICAL HIGH-VOLUME DATA INSTRUCTIONS:\n",
        "- Start with these EXACT import statements:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "- Generate ONLY Python code after the imports\n",
        "- Include data loading and preprocessing\n",
        "- Add statistical analysis\n",
        "- Create visualizations using matplotlib and seaborn\n",
        "\n",
        "COMPREHENSIVE HIGH-VOLUME DATA HANDLING:\n",
        "- Use UNIQUE variable names for each data subset (e.g., df_sample_1, df_sample_2, df_numeric_only, df_categorical_only)\n",
        "- When sampling data, use DIFFERENT variable names for each sample\n",
        "- Track which data has been used to avoid overlap\n",
        "- Use descriptive variable names that indicate the data subset\n",
        "- For multiple visualizations, use different data subsets or samples\n",
        "- IMPORTANT: Save all plots using plt.savefig() with descriptive filenames\n",
        "- Include error handling with try-except blocks\n",
        "- Add comments using # symbol\n",
        "- Do NOT include any explanatory text\n",
        "- Do NOT include \"Certainly!\" or \"Let's break down\"\n",
        "- Output should be executable Python code only\n",
        "\n",
        "DATA TYPE SAFETY REQUIREMENTS:\n",
        "- ALWAYS check data types before mathematical operations\n",
        "- Use pd.to_numeric() with errors='coerce' for safe conversion\n",
        "- Handle categorical data appropriately\n",
        "- Never assume data types without validation\n",
        "- Use df.select_dtypes(include=[np.number]) for numeric operations\n",
        "- Use df.select_dtypes(include=['object']) for categorical operations\n",
        "\n",
        "VISUALIZATION REQUIREMENTS FOR HIGH-VOLUME DATA:\n",
        "- Create at least 5 different types of visualizations\n",
        "- Use DIFFERENT data subsets for each visualization\n",
        "- Use plt.savefig('figure_1.png'), plt.savefig('figure_2.png'), etc.\n",
        "- Include scatter plots, line plots, bar charts, heatmaps, and distribution plots\n",
        "- Sample different portions of data for each visualization\n",
        "- Use unique variable names for each data subset\n",
        "- Make sure to call plt.show() after each plot\n",
        "\n",
        "EXAMPLE VARIABLE NAMING FOR HIGH-VOLUME DATA:\n",
        "- df_sample_1 = df.head(1000)  # First 1000 rows\n",
        "- df_sample_2 = df.tail(1000)  # Last 1000 rows\n",
        "- df_sample_3 = df.sample(1000)  # Random sample\n",
        "- df_numeric_only = df.select_dtypes(include=[np.number])  # Numeric columns only\n",
        "- df_categorical_only = df.select_dtypes(include=['object'])  # Categorical columns only\n",
        "- df_subset_1 = df[df['column'] > threshold]  # Filtered subset\n",
        "- df_subset_2 = df.groupby('category').head(500)  # Grouped subset\n",
        "\n",
        "Generate the complete Python code starting with the imports:\"\"\"\n",
        "        else:\n",
        "            task = f\"\"\"Refine the following code based on the review feedback:\n",
        "\n",
        "PREVIOUS CODE:\n",
        "{self.state.context.get('previous_code', '')}\n",
        "\n",
        "REVIEW FEEDBACK:\n",
        "{self.state.context.get('review_feedback', '')}\n",
        "\n",
        "ITERATION: {iteration}\n",
        "\n",
        "CRITICAL INSTRUCTIONS FOR HIGH-VOLUME DATA:\n",
        "- Start with these EXACT import statements:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "- Fix any issues identified in the feedback\n",
        "- Improve code quality and functionality\n",
        "- Ensure all visualizations are properly saved\n",
        "- Use UNIQUE variable names for each data subset\n",
        "- Avoid reusing the same data in multiple visualizations\n",
        "- Generate ONLY executable Python code\n",
        "- Do NOT include any explanatory text\n",
        "\n",
        "Generate the improved Python code:\"\"\"\n",
        "\n",
        "        return self.execute_with_retry(task)\n",
        "\n",
        "    def _create_data_context(self, csv_data: Dict[str, pd.DataFrame]) -> str:\n",
        "        context = \"\"\n",
        "        for name, df in csv_data.items():\n",
        "            context += f\"\\nDataset '{name}':\\n\"\n",
        "            context += f\"- Shape: {df.shape}\\n\"\n",
        "            context += f\"- Columns: {list(df.columns)}\\n\"\n",
        "            context += f\"- Data types: {df.dtypes.to_dict()}\\n\"\n",
        "            context += f\"- Missing values: {df.isnull().sum().to_dict()}\\n\"\n",
        "            context += f\"- Sample: {df.head(2).to_dict()}\\n\"\n",
        "\n",
        "            if df.shape[0] > 10000:\n",
        "                context += f\"- HIGH-VOLUME DATA: {df.shape[0]} rows - Use sampling and subsets for visualizations\\n\"\n",
        "                context += f\"- Recommended: Create multiple samples and subsets for different analyses\\n\"\n",
        "            elif df.shape[0] > 1000:\n",
        "                context += f\"- MEDIUM-VOLUME DATA: {df.shape[0]} rows - Consider sampling for complex visualizations\\n\"\n",
        "            else:\n",
        "                context += f\"- SMALL DATA: {df.shape[0]} rows - Can use full dataset for visualizations\\n\"\n",
        "        return context\n",
        "\n",
        "class DataScientistReviewerAgent(BaseAgent):\n",
        "    def __init__(self, openrouter_client: OpenRouterClient):\n",
        "        super().__init__(\n",
        "            name=\"Data Scientist Reviewer\",\n",
        "            role=\"Senior Data Science Code Reviewer\",\n",
        "            expertise=\"code review, quality assurance, debugging, and best practices\",\n",
        "            openrouter_client=openrouter_client\n",
        "        )\n",
        "\n",
        "    def execute(self, code: str, analysis_plan: str, iteration: int) -> str:\n",
        "        task = f\"\"\"Review the generated Python code and provide detailed feedback.\n",
        "\n",
        "ITERATION: {iteration}\n",
        "\n",
        "ORIGINAL ANALYSIS PLAN:\n",
        "{analysis_plan}\n",
        "\n",
        "CODE TO REVIEW:\n",
        "{code}\n",
        "\n",
        "Review criteria:\n",
        "1. Code correctness and logic\n",
        "2. Adherence to analysis plan\n",
        "3. Best practices and conventions\n",
        "4. Error handling and robustness\n",
        "5. Performance and efficiency\n",
        "6. Documentation and comments\n",
        "7. Visualization quality\n",
        "8. Statistical validity\n",
        "9. HIGH-VOLUME DATA handling - Check for unique variable names\n",
        "10. Data subset management - Ensure no data overlap\n",
        "11. Data type safety - Verify proper type handling\n",
        "\n",
        "Provide:\n",
        "- Specific feedback on issues\n",
        "- Suggestions for improvement\n",
        "- Code quality rating (1-10)\n",
        "- Recommendation: APPROVE, REVISE, or REJECT\n",
        "\n",
        "Write your review in clear, professional plain English without any markdown formatting.\"\"\"\n",
        "\n",
        "        return self.execute_with_retry(task)\n",
        "\n",
        "class BusinessInsightsTranslatorAgent(BaseAgent):\n",
        "    def __init__(self, openrouter_client: OpenRouterClient):\n",
        "        super().__init__(\n",
        "            name=\"Business Insights Translator\",\n",
        "            role=\"Business Intelligence Translator\",\n",
        "            expertise=\"translating technical analysis results into business-friendly insights and actionable recommendations\",\n",
        "            openrouter_client=openrouter_client\n",
        "        )\n",
        "\n",
        "    def execute(self, analysis_results: Dict[str, Any], data_context: str) -> str:\n",
        "        task = f\"\"\"Translate the technical analysis results into clear, business-friendly insights that non-technical stakeholders can understand and act upon.\n",
        "\n",
        "DATA CONTEXT:\n",
        "{data_context}\n",
        "\n",
        "TECHNICAL ANALYSIS RESULTS:\n",
        "{json.dumps(analysis_results, indent=2)}\n",
        "\n",
        "Your task is to:\n",
        "1. Identify the key findings from the technical analysis\n",
        "2. Translate statistical results into business implications\n",
        "3. Explain what the data means in practical terms\n",
        "4. Highlight trends, patterns, and anomalies\n",
        "5. Provide actionable insights for decision-making\n",
        "6. Avoid technical jargon and use plain business language\n",
        "7. Focus on what matters most for business strategy\n",
        "\n",
        "Structure your response as:\n",
        "1. Executive Summary of Key Findings\n",
        "2. Data Trends and Patterns Identified\n",
        "3. Business Implications and Opportunities\n",
        "4. Risk Factors and Concerns\n",
        "5. Recommended Actions and Next Steps\n",
        "\n",
        "Write your analysis in clear, professional plain English without any markdown formatting. Make it accessible to business executives and decision-makers.\"\"\"\n",
        "\n",
        "        return self.execute_with_retry(task)\n",
        "\n",
        "class DecisionMakerAgent(BaseAgent):\n",
        "    def __init__(self, openrouter_client: OpenRouterClient):\n",
        "        super().__init__(\n",
        "            name=\"Decision Maker\",\n",
        "            role=\"Senior Business Analyst\",\n",
        "            expertise=\"business intelligence, decision making, and report generation\",\n",
        "            openrouter_client=openrouter_client\n",
        "        )\n",
        "\n",
        "    def execute(self, all_outputs: Dict[str, str], analysis_results: Dict[str, Any], business_insights: str) -> str:\n",
        "        clean_outputs = {}\n",
        "        for key, value in all_outputs.items():\n",
        "            if key in [\"data_understander\", \"market_researcher\", \"planner\", \"decision_maker\"]:\n",
        "                clean_outputs[key] = value\n",
        "\n",
        "        task = f\"\"\"Compile a comprehensive, professional analysis report based on clean agent outputs, analysis results, and business insights.\n",
        "\n",
        "CLEAN AGENT OUTPUTS (NO ITERATION DATA):\n",
        "{json.dumps(clean_outputs, indent=2)}\n",
        "\n",
        "FINAL ANALYSIS RESULTS:\n",
        "{json.dumps(analysis_results, indent=2)}\n",
        "\n",
        "BUSINESS INSIGHTS TRANSLATION:\n",
        "{business_insights}\n",
        "\n",
        "Create a professional report with:\n",
        "1. Executive Summary with key findings\n",
        "2. Data Overview and Quality Assessment\n",
        "3. Market Context and Industry Insights\n",
        "4. Detailed Analysis Findings and Results\n",
        "5. Business Implications and Insights\n",
        "6. Key Insights and Patterns Discovered\n",
        "7. Strategic Recommendations for Action\n",
        "8. Implementation Roadmap with Timeline\n",
        "9. Risk Assessment and Mitigation Plans\n",
        "10. Conclusion and Next Steps\n",
        "\n",
        "Write your report in clear, professional plain English without any markdown formatting. Use proper paragraph structure and complete sentences.\"\"\"\n",
        "\n",
        "        return self.execute_with_retry(task)\n",
        "\n",
        "# Cell 7: Main orchestrator that runs all agents\n",
        "class MultiAgentOrchestrator:\n",
        "    def __init__(self, openrouter_api_key: str, brave_api_key: str, model: str = \"openai/gpt-4o-mini\"):\n",
        "        self.openrouter_client = OpenRouterClient(openrouter_api_key, model)\n",
        "        self.brave_client = BraveSearchClient(brave_api_key)\n",
        "\n",
        "        self.agents = {\n",
        "            \"data_understander\": DataUnderstanderAgent(self.openrouter_client),\n",
        "            \"market_researcher\": MarketResearcherAgent(self.openrouter_client, self.brave_client),\n",
        "            \"planner\": PlannerAgent(self.openrouter_client),\n",
        "            \"coder\": DataScientistCoderAgent(self.openrouter_client),\n",
        "            \"reviewer\": DataScientistReviewerAgent(self.openrouter_client),\n",
        "            \"business_translator\": BusinessInsightsTranslatorAgent(self.openrouter_client),\n",
        "            \"decision_maker\": DecisionMakerAgent(self.openrouter_client)\n",
        "        }\n",
        "\n",
        "        self.workflow_state = {\n",
        "            \"csv_data\": {},\n",
        "            \"agent_outputs\": {},\n",
        "            \"analysis_results\": {},\n",
        "            \"business_insights\": \"\",\n",
        "            \"current_step\": 0,\n",
        "            \"total_steps\": 7,\n",
        "            \"status\": \"initialized\",\n",
        "            \"saved_figures\": [],\n",
        "            \"iteration_results\": {},\n",
        "            \"successful_iteration\": None,\n",
        "            \"final_code_approved\": False,\n",
        "            \"analysis_successful\": False,\n",
        "            \"executed_code\": \"\",\n",
        "            \"analysis_summary\": \"\",\n",
        "            \"final_execution_done\": False,\n",
        "            \"data_volume_info\": {}\n",
        "        }\n",
        "\n",
        "    def load_csv_data(self, csv_files: Dict[str, str]) -> bool:\n",
        "        try:\n",
        "            for filename, content in csv_files.items():\n",
        "                df = pd.read_csv(io.StringIO(content))\n",
        "                self.workflow_state[\"csv_data\"][filename] = df\n",
        "\n",
        "                self.workflow_state[\"data_volume_info\"][filename] = {\n",
        "                    \"rows\": df.shape[0],\n",
        "                    \"columns\": df.shape[1],\n",
        "                    \"size_category\": \"HIGH\" if df.shape[0] > 10000 else \"MEDIUM\" if df.shape[0] > 1000 else \"SMALL\"\n",
        "                }\n",
        "\n",
        "            print(f\"Loaded {len(csv_files)} CSV files successfully\")\n",
        "\n",
        "            for filename, info in self.workflow_state[\"data_volume_info\"].items():\n",
        "                print(f\"{filename}: {info['rows']} rows × {info['columns']} columns ({info['size_category']} volume)\")\n",
        "\n",
        "            return True\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading CSV data: {str(e)}\")\n",
        "            return False\n",
        "\n",
        "    def execute_workflow(self) -> Dict[str, Any]:\n",
        "        print(\"Starting Multi-Agent Analytics Workflow...\")\n",
        "        self.workflow_state[\"status\"] = \"running\"\n",
        "\n",
        "        try:\n",
        "            print(\"\\nStep 1: Data Understanding\")\n",
        "            data_insights = self.agents[\"data_understander\"].execute(self.workflow_state[\"csv_data\"])\n",
        "            self.workflow_state[\"agent_outputs\"][\"data_understander\"] = data_insights\n",
        "            self.workflow_state[\"current_step\"] = 1\n",
        "\n",
        "            print(\"\\nStep 2: Market Research\")\n",
        "            market_insights = self.agents[\"market_researcher\"].execute(data_insights)\n",
        "            self.workflow_state[\"agent_outputs\"][\"market_researcher\"] = market_insights\n",
        "            self.workflow_state[\"current_step\"] = 2\n",
        "\n",
        "            print(\"\\nStep 3: Analysis Planning\")\n",
        "            analysis_plan = self.agents[\"planner\"].execute(data_insights, market_insights)\n",
        "            self.workflow_state[\"agent_outputs\"][\"planner\"] = analysis_plan\n",
        "            self.workflow_state[\"current_step\"] = 3\n",
        "\n",
        "            print(\"\\nSteps 4 & 5: Iterative Coding and Review\")\n",
        "            final_code = self._execute_coding_iteration_loop(analysis_plan)\n",
        "            self.workflow_state[\"agent_outputs\"][\"final_code\"] = final_code\n",
        "            self.workflow_state[\"executed_code\"] = final_code\n",
        "            self.workflow_state[\"current_step\"] = 5\n",
        "\n",
        "            print(\"\\nExecuting Final Analysis Code\")\n",
        "            analysis_results = self._execute_analysis_code(final_code, test_mode=False)\n",
        "            self.workflow_state[\"analysis_results\"] = analysis_results\n",
        "            self.workflow_state[\"final_execution_done\"] = True\n",
        "\n",
        "            self.workflow_state[\"analysis_summary\"] = self._generate_analysis_summary(analysis_results)\n",
        "\n",
        "            print(\"\\nStep 6: Business Insights Translation\")\n",
        "            business_insights = self.agents[\"business_translator\"].execute(analysis_results, data_insights)\n",
        "            self.workflow_state[\"agent_outputs\"][\"business_translator\"] = business_insights\n",
        "            self.workflow_state[\"business_insights\"] = business_insights\n",
        "            self.workflow_state[\"current_step\"] = 6\n",
        "\n",
        "            print(\"\\nStep 7: Decision Making and Report Generation\")\n",
        "            final_report = self.agents[\"decision_maker\"].execute(\n",
        "                self.workflow_state[\"agent_outputs\"],\n",
        "                analysis_results,\n",
        "                business_insights\n",
        "            )\n",
        "            self.workflow_state[\"agent_outputs\"][\"decision_maker\"] = final_report\n",
        "            self.workflow_state[\"current_step\"] = 7\n",
        "\n",
        "            self.workflow_state[\"status\"] = \"completed\"\n",
        "            print(\"\\nMulti-Agent Workflow Completed Successfully!\")\n",
        "\n",
        "            return self.workflow_state\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nWorkflow failed: {str(e)}\")\n",
        "            print(f\"Workflow completed up to step {self.workflow_state['current_step']}\")\n",
        "            self.workflow_state[\"status\"] = \"error\"\n",
        "            self.workflow_state[\"error\"] = str(e)\n",
        "\n",
        "            try:\n",
        "                print(\"\\nGenerating partial report...\")\n",
        "                final_report = self.agents[\"decision_maker\"].execute(\n",
        "                    self.workflow_state[\"agent_outputs\"],\n",
        "                    self.workflow_state.get(\"analysis_results\", {}),\n",
        "                    self.workflow_state.get(\"business_insights\", \"\")\n",
        "                )\n",
        "                self.workflow_state[\"agent_outputs\"][\"decision_maker\"] = final_report\n",
        "            except:\n",
        "                print(\"Could not generate partial report\")\n",
        "\n",
        "            return self.workflow_state\n",
        "\n",
        "    def _execute_coding_iteration_loop(self, analysis_plan: str, max_iterations: int = 5) -> str:\n",
        "        current_code = \"\"\n",
        "        approved_code = None\n",
        "\n",
        "        for iteration in range(max_iterations):\n",
        "            print(f\"\\nCoding Iteration {iteration + 1}/{max_iterations}\")\n",
        "\n",
        "            if iteration == 0:\n",
        "                current_code = self.agents[\"coder\"].execute(analysis_plan, self.workflow_state[\"csv_data\"], iteration + 1)\n",
        "            else:\n",
        "                self.agents[\"coder\"].update_context(\"previous_code\", current_code)\n",
        "                self.agents[\"coder\"].update_context(\"review_feedback\", self.workflow_state[\"agent_outputs\"].get(f\"reviewer_feedback_iter_{iteration}\", \"\"))\n",
        "                current_code = self.agents[\"coder\"].execute(analysis_plan, self.workflow_state[\"csv_data\"], iteration + 1)\n",
        "\n",
        "            print(f\"Testing code from iteration {iteration + 1}\")\n",
        "            test_results = self._execute_analysis_code(current_code, test_mode=True)\n",
        "\n",
        "            if test_results.get(\"execution_status\") == \"success\":\n",
        "                print(f\"Analysis successful in iteration {iteration + 1}\")\n",
        "                self.workflow_state[\"analysis_successful\"] = True\n",
        "\n",
        "                self.workflow_state[\"iteration_results\"][\"successful_analysis\"] = test_results\n",
        "                self.workflow_state[\"successful_iteration\"] = iteration + 1\n",
        "\n",
        "                print(f\"Analysis working! Stopping iterations immediately at iteration {iteration + 1}\")\n",
        "                approved_code = current_code\n",
        "                break\n",
        "\n",
        "            if iteration == 0:\n",
        "                self.workflow_state[\"iteration_results\"][f\"iteration_{iteration + 1}\"] = test_results\n",
        "\n",
        "            review_feedback = self.agents[\"reviewer\"].execute(current_code, analysis_plan, iteration + 1)\n",
        "            self.workflow_state[\"agent_outputs\"][f\"reviewer_feedback_iter_{iteration + 1}\"] = review_feedback\n",
        "\n",
        "            if \"APPROVE\" in review_feedback.upper():\n",
        "                print(f\"Code approved after {iteration + 1} iterations\")\n",
        "                approved_code = current_code\n",
        "                self.workflow_state[\"successful_iteration\"] = iteration + 1\n",
        "                self.workflow_state[\"final_code_approved\"] = True\n",
        "                break\n",
        "            elif \"REJECT\" in review_feedback.upper() and iteration == max_iterations - 1:\n",
        "                print(\"Code rejected after all iterations, using latest version\")\n",
        "                approved_code = current_code\n",
        "                break\n",
        "\n",
        "            print(f\"Review feedback received, continuing to iteration {iteration + 2}\")\n",
        "\n",
        "        return approved_code or current_code\n",
        "\n",
        "    def _execute_analysis_code(self, code: str, test_mode: bool = False) -> Dict[str, Any]:\n",
        "        try:\n",
        "            exec_globals = {\n",
        "                '__builtins__': __builtins__,\n",
        "                'pd': pd, 'np': np, 'plt': plt, 'sns': sns,\n",
        "                'go': go, 'px': px, 'make_subplots': make_subplots,\n",
        "                'json': json, 'time': time, 'warnings': warnings,\n",
        "                'os': os, 'io': io, 'base64': base64, 're': re\n",
        "            }\n",
        "\n",
        "            for name, df in self.workflow_state[\"csv_data\"].items():\n",
        "                clean_name = name.replace('.csv', '').replace(' ', '_').replace('-', '_')\n",
        "\n",
        "                df_copy = df.copy(deep=True)\n",
        "\n",
        "                exec_globals[f\"df_{clean_name}\"] = df_copy\n",
        "                exec_globals[f\"df_{clean_name}_types\"] = df_copy.dtypes.to_dict()\n",
        "                exec_globals[f\"df_{clean_name}_numeric\"] = df_copy.select_dtypes(include=[np.number])\n",
        "                exec_globals[f\"df_{clean_name}_categorical\"] = df_copy.select_dtypes(include=['object'])\n",
        "                exec_globals[f\"df_{clean_name}_info\"] = {\n",
        "                    \"shape\": df_copy.shape,\n",
        "                    \"columns\": list(df_copy.columns),\n",
        "                    \"dtypes\": df_copy.dtypes.to_dict(),\n",
        "                    \"has_mixed_types\": any(df_copy[col].dtype == 'object' for col in df_copy.columns)\n",
        "                }\n",
        "\n",
        "            exec_globals['safe_numeric_conversion'] = lambda series: pd.to_numeric(series, errors='coerce')\n",
        "            exec_globals['safe_string_conversion'] = lambda series: series.astype(str)\n",
        "            exec_globals['check_data_types'] = lambda df: df.dtypes.to_dict()\n",
        "\n",
        "            import matplotlib\n",
        "            matplotlib.use('Agg')\n",
        "            plt.clf()\n",
        "            plt.cla()\n",
        "            plt.close('all')\n",
        "\n",
        "            essential_imports = \"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def safe_analysis(df, column):\n",
        "    if df[column].dtype == 'object':\n",
        "        return df[column].value_counts()\n",
        "    else:\n",
        "        return df[column].describe()\n",
        "\n",
        "def safe_visualization(df, column):\n",
        "    if df[column].dtype == 'object':\n",
        "        plt.figure()\n",
        "        df[column].value_counts().head(10).plot(kind='bar')\n",
        "        plt.title(f'Top 10 {column}')\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.tight_layout()\n",
        "    else:\n",
        "        plt.figure()\n",
        "        df[column].hist(bins=30)\n",
        "        plt.title(f'Distribution of {column}')\n",
        "        plt.tight_layout()\n",
        "\"\"\"\n",
        "\n",
        "            full_code = essential_imports + \"\\n\" + code\n",
        "\n",
        "            exec(full_code, exec_globals)\n",
        "\n",
        "            if not test_mode and not self.workflow_state[\"final_execution_done\"]:\n",
        "                self._save_generated_figures()\n",
        "\n",
        "            results = {}\n",
        "            analysis_summary_parts = []\n",
        "\n",
        "            for key, value in exec_globals.items():\n",
        "                if not key.startswith('_') and key not in ['pd', 'np', 'plt', 'sns', 'go', 'px', 'make_subplots', 'json', 'time', 'warnings', 'os', 'io', 'base64', 're', 'safe_numeric_conversion', 'safe_string_conversion', 'check_data_types', 'safe_analysis', 'safe_visualization']:\n",
        "                    if isinstance(value, (pd.DataFrame, pd.Series, np.ndarray, dict, list, str, int, float)):\n",
        "                        results[key] = str(value)[:1000]\n",
        "\n",
        "                        if isinstance(value, pd.DataFrame):\n",
        "                            analysis_summary_parts.append(f\"DataFrame '{key}': {value.shape[0]} rows, {value.shape[1]} columns\")\n",
        "                        elif isinstance(value, pd.Series):\n",
        "                            analysis_summary_parts.append(f\"Series '{key}': {len(value)} values\")\n",
        "                        elif isinstance(value, (int, float)):\n",
        "                            analysis_summary_parts.append(f\"Metric '{key}': {value}\")\n",
        "                        elif isinstance(value, str) and len(value) < 200:\n",
        "                            analysis_summary_parts.append(f\"Result '{key}': {value}\")\n",
        "\n",
        "            try:\n",
        "                if plt.get_fignums():\n",
        "                    fig_count = len(plt.get_fignums())\n",
        "                    print(f\"Generated {fig_count} visualizations\")\n",
        "                    results['matplotlib_figures'] = fig_count\n",
        "                    results['visualization_count'] = fig_count\n",
        "                    analysis_summary_parts.append(f\"Generated {fig_count} visualizations\")\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            results['execution_status'] = 'success'\n",
        "            results['analysis_summary'] = '; '.join(analysis_summary_parts)\n",
        "\n",
        "            return results\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Code execution failed: {str(e)}\")\n",
        "            print(f\"Code that failed:\\n{code[:500]}...\")\n",
        "            return {\n",
        "                \"error\": str(e),\n",
        "                \"traceback\": traceback.format_exc(),\n",
        "                \"execution_status\": \"failed\",\n",
        "                \"analysis_summary\": f\"Code execution failed: {str(e)}\"\n",
        "            }\n",
        "\n",
        "    def _save_generated_figures(self) -> None:\n",
        "        try:\n",
        "            import matplotlib.pyplot as plt\n",
        "\n",
        "            self.workflow_state[\"saved_figures\"] = []\n",
        "\n",
        "            current_figures = list(plt.get_fignums())\n",
        "\n",
        "            for i, fig_num in enumerate(current_figures):\n",
        "                try:\n",
        "                    fig = plt.figure(fig_num)\n",
        "                    filename = f\"figure_{i+1}.png\"\n",
        "\n",
        "                    fig.savefig(filename, dpi=300, bbox_inches='tight')\n",
        "                    self.workflow_state[\"saved_figures\"].append(filename)\n",
        "                    print(f\"Saved visualization: {filename}\")\n",
        "\n",
        "                    plt.close(fig)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error saving figure {fig_num}: {str(e)}\")\n",
        "\n",
        "            plt.clf()\n",
        "            plt.cla()\n",
        "            plt.close('all')\n",
        "\n",
        "            import gc\n",
        "            gc.collect()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Could not save figures: {str(e)}\")\n",
        "\n",
        "    def _generate_analysis_summary(self, analysis_results: Dict[str, Any]) -> str:\n",
        "        if not analysis_results:\n",
        "            return \"No analysis results available.\"\n",
        "\n",
        "        summary_parts = []\n",
        "\n",
        "        if \"execution_status\" in analysis_results:\n",
        "            status = analysis_results[\"execution_status\"]\n",
        "            if status == \"success\":\n",
        "                summary_parts.append(\"Analysis executed successfully.\")\n",
        "            else:\n",
        "                summary_parts.append(f\"Analysis execution failed: {analysis_results.get('error', 'Unknown error')}\")\n",
        "\n",
        "        if \"visualization_count\" in analysis_results:\n",
        "            count = analysis_results[\"visualization_count\"]\n",
        "            summary_parts.append(f\"Generated {count} data visualizations.\")\n",
        "\n",
        "        if \"analysis_summary\" in analysis_results:\n",
        "            summary_parts.append(f\"Analysis results: {analysis_results['analysis_summary']}\")\n",
        "\n",
        "        for key, value in analysis_results.items():\n",
        "            if key not in [\"execution_status\", \"visualization_count\", \"analysis_summary\", \"error\", \"traceback\"]:\n",
        "                if isinstance(value, str) and len(value) < 100:\n",
        "                    summary_parts.append(f\"{key}: {value}\")\n",
        "\n",
        "        return \" \".join(summary_parts)\n",
        "\n",
        "# Cell 8: PDF report generator\n",
        "class PDFReportGenerator:\n",
        "    def __init__(self):\n",
        "        self.styles = getSampleStyleSheet()\n",
        "        self.title_style = ParagraphStyle(\n",
        "            'CustomTitle',\n",
        "            parent=self.styles['Heading1'],\n",
        "            fontSize=18,\n",
        "            spaceAfter=30,\n",
        "            alignment=TA_CENTER,\n",
        "            textColor=colors.darkblue\n",
        "        )\n",
        "        self.heading_style = ParagraphStyle(\n",
        "            'CustomHeading',\n",
        "            parent=self.styles['Heading2'],\n",
        "            fontSize=14,\n",
        "            spaceAfter=12,\n",
        "            textColor=colors.black\n",
        "        )\n",
        "        self.body_style = ParagraphStyle(\n",
        "            'CustomBody',\n",
        "            parent=self.styles['Normal'],\n",
        "            fontSize=11,\n",
        "            spaceAfter=6,\n",
        "            alignment=TA_LEFT\n",
        "        )\n",
        "        self.bullet_style = ParagraphStyle(\n",
        "            'CustomBullet',\n",
        "            parent=self.styles['Normal'],\n",
        "            fontSize=11,\n",
        "            spaceAfter=6,\n",
        "            leftIndent=20,\n",
        "            bulletIndent=10,\n",
        "            alignment=TA_LEFT\n",
        "        )\n",
        "\n",
        "    def _add_images_to_pdf(self, story: List, image_paths: List[str]) -> None:\n",
        "        for image_path in image_paths:\n",
        "            try:\n",
        "                if os.path.exists(image_path):\n",
        "                    img = Image(image_path)\n",
        "\n",
        "                    page_width = A4[0] - 2*inch\n",
        "                    if img.imageWidth > page_width:\n",
        "                        img.drawWidth = page_width\n",
        "                        img.drawHeight = img.imageHeight * (page_width / img.imageWidth)\n",
        "\n",
        "                    story.append(img)\n",
        "                    story.append(Spacer(1, 12))\n",
        "\n",
        "                    caption = f\"Figure: {image_path.replace('.png', '').replace('_', ' ').title()}\"\n",
        "                    story.append(Paragraph(caption, self.body_style))\n",
        "                    story.append(Spacer(1, 12))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Could not add image {image_path}: {str(e)}\")\n",
        "\n",
        "    def _clean_text(self, text: str) -> str:\n",
        "        text = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', text)\n",
        "        text = re.sub(r'\\*(.*?)\\*', r'\\1', text)\n",
        "        text = re.sub(r'##\\s*(.*)', r'\\1', text)\n",
        "        text = re.sub(r'#\\s*(.*)', r'\\1', text)\n",
        "        text = re.sub(r'`(.*?)`', r'\\1', text)\n",
        "        text = re.sub(r'\\[(.*?)\\]\\(.*?\\)', r'\\1', text)\n",
        "\n",
        "        text = re.sub(r'Certainly!.*?', '', text)\n",
        "        text = re.sub(r\"Let's break down.*?\\.\", '', text)\n",
        "        text = re.sub(r'Here\\'s.*?\\.', '', text)\n",
        "\n",
        "        return text.strip()\n",
        "\n",
        "    def _format_content_for_pdf(self, content: str) -> List:\n",
        "        story = []\n",
        "\n",
        "        cleaned_content = self._clean_text(content)\n",
        "\n",
        "        paragraphs = cleaned_content.split('\\n\\n')\n",
        "\n",
        "        for para in paragraphs:\n",
        "            para = para.strip()\n",
        "            if not para:\n",
        "                continue\n",
        "\n",
        "            if (len(para) < 100 and\n",
        "                (para.startswith(('1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.')) or\n",
        "                 para.isupper() or\n",
        "                 para.endswith(':'))):\n",
        "                story.append(Paragraph(para, self.heading_style))\n",
        "            else:\n",
        "                story.append(Paragraph(para, self.body_style))\n",
        "\n",
        "        return story\n",
        "\n",
        "    def generate_pdf_report(self, workflow_state: Dict[str, Any], filename: str) -> str:\n",
        "        doc = SimpleDocTemplate(filename, pagesize=A4)\n",
        "        story = []\n",
        "\n",
        "        story.append(Paragraph(\"Multi-Agent Analytics Report\", self.title_style))\n",
        "        story.append(Spacer(1, 20))\n",
        "\n",
        "        story.append(Paragraph(\"Executive Summary\", self.heading_style))\n",
        "        story.append(Paragraph(\n",
        "            \"This comprehensive analysis was conducted using a multi-agent AI system with advanced prompt engineering protocols. \"\n",
        "            \"The analysis covers data understanding, market research, statistical analysis, and strategic recommendations.\",\n",
        "            self.body_style\n",
        "        ))\n",
        "        story.append(Spacer(1, 12))\n",
        "\n",
        "        if \"csv_data\" in workflow_state:\n",
        "            story.append(Paragraph(\"Data Overview\", self.heading_style))\n",
        "            data_text = \"Analysis conducted on the following datasets:\"\n",
        "            story.append(Paragraph(data_text, self.body_style))\n",
        "\n",
        "            for name, df in workflow_state[\"csv_data\"].items():\n",
        "                volume_info = workflow_state.get(\"data_volume_info\", {}).get(name, {})\n",
        "                volume_category = volume_info.get(\"size_category\", \"UNKNOWN\")\n",
        "                story.append(Paragraph(f\"• {name}: {df.shape[0]} rows × {df.shape[1]} columns ({volume_category} volume)\", self.bullet_style))\n",
        "            story.append(Spacer(1, 12))\n",
        "\n",
        "        if \"agent_outputs\" in workflow_state:\n",
        "            agent_order = [\n",
        "                (\"data_understander\", \"Step 1: Data Understanding and Profiling\"),\n",
        "                (\"market_researcher\", \"Step 2: Market Research and Industry Analysis\"),\n",
        "                (\"planner\", \"Step 3: Analysis Planning and Strategy\")\n",
        "            ]\n",
        "\n",
        "            for agent_key, section_title in agent_order:\n",
        "                if agent_key in workflow_state[\"agent_outputs\"]:\n",
        "                    story.append(Paragraph(section_title, self.heading_style))\n",
        "                    formatted_content = self._format_content_for_pdf(workflow_state[\"agent_outputs\"][agent_key])\n",
        "                    story.extend(formatted_content)\n",
        "                    story.append(Spacer(1, 12))\n",
        "\n",
        "        if \"analysis_results\" in workflow_state and workflow_state[\"analysis_results\"]:\n",
        "            story.append(Paragraph(\"Step 4-5: Statistical Analysis Results\", self.heading_style))\n",
        "\n",
        "            if \"execution_status\" in workflow_state[\"analysis_results\"]:\n",
        "                status = workflow_state[\"analysis_results\"][\"execution_status\"]\n",
        "                if status == \"success\":\n",
        "                    story.append(Paragraph(\"Analysis executed successfully\", self.body_style))\n",
        "                else:\n",
        "                    story.append(Paragraph(f\"Analysis execution failed: {workflow_state['analysis_results'].get('error', 'Unknown error')}\", self.body_style))\n",
        "\n",
        "            if \"visualization_count\" in workflow_state[\"analysis_results\"]:\n",
        "                count = workflow_state[\"analysis_results\"][\"visualization_count\"]\n",
        "                story.append(Paragraph(f\"Generated {count} data visualizations\", self.body_style))\n",
        "\n",
        "            story.append(Spacer(1, 6))\n",
        "            story.append(Spacer(1, 12))\n",
        "\n",
        "        if \"saved_figures\" in workflow_state and workflow_state[\"saved_figures\"]:\n",
        "            story.append(Paragraph(\"Data Visualizations\", self.heading_style))\n",
        "            story.append(Paragraph(\n",
        "                f\"The following {len(workflow_state['saved_figures'])} visualizations were generated during the analysis:\",\n",
        "                self.body_style\n",
        "            ))\n",
        "            story.append(Spacer(1, 12))\n",
        "            self._add_images_to_pdf(story, workflow_state[\"saved_figures\"])\n",
        "\n",
        "        if \"successful_iteration\" in workflow_state and workflow_state[\"successful_iteration\"]:\n",
        "            story.append(Paragraph(\"Code Development Process\", self.heading_style))\n",
        "            story.append(Paragraph(\n",
        "                f\"The analysis code was successfully developed and approved after {workflow_state['successful_iteration']} iteration(s). \"\n",
        "                f\"The final code was {'approved' if workflow_state.get('final_code_approved', False) else 'used after review process'}.\",\n",
        "                self.body_style\n",
        "            ))\n",
        "            story.append(Spacer(1, 12))\n",
        "\n",
        "        if \"agent_outputs\" in workflow_state and \"business_translator\" in workflow_state[\"agent_outputs\"]:\n",
        "            story.append(Paragraph(\"Step 6: Business Insights Translation\", self.heading_style))\n",
        "            formatted_content = self._format_content_for_pdf(workflow_state[\"agent_outputs\"][\"business_translator\"])\n",
        "            story.extend(formatted_content)\n",
        "            story.append(Spacer(1, 12))\n",
        "\n",
        "        if \"agent_outputs\" in workflow_state and \"decision_maker\" in workflow_state[\"agent_outputs\"]:\n",
        "            story.append(Paragraph(\"Step 7: Final Analysis Results and Recommendations\", self.heading_style))\n",
        "            formatted_content = self._format_content_for_pdf(workflow_state[\"agent_outputs\"][\"decision_maker\"])\n",
        "            story.extend(formatted_content)\n",
        "            story.append(Spacer(1, 12))\n",
        "\n",
        "        story.append(Spacer(1, 20))\n",
        "        story.append(Paragraph(\"Report generated by Multi-Agent Analytics System\", self.body_style))\n",
        "        story.append(Paragraph(\"Powered by Advanced AI Agents with Chain-of-Thought Reasoning\", self.body_style))\n",
        "\n",
        "        doc.build(story)\n",
        "        return filename\n",
        "\n",
        "# Cell 9: User interface for file upload and analysis\n",
        "def create_file_upload_ui() -> widgets.VBox:\n",
        "    upload_widget = widgets.FileUpload(\n",
        "        accept='.csv',\n",
        "        multiple=True,\n",
        "        description='Upload CSV Files',\n",
        "        style={'button_color': '#667eea'}\n",
        "    )\n",
        "\n",
        "    api_key_input = widgets.Password(\n",
        "        placeholder='Enter OpenRouter API Key',\n",
        "        description='OpenRouter API Key:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    brave_key_input = widgets.Password(\n",
        "        placeholder='Enter Brave Search API Key',\n",
        "        description='Brave API Key:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    model_dropdown = widgets.Dropdown(\n",
        "        options=[\n",
        "            ('GPT OSS 120B', 'openai/gpt-4o-mini'),\n",
        "            ('DeepSeek R1', 'deepseek/deepseek-r1'),\n",
        "            ('Claude 3.5 Sonnet', 'anthropic/claude-3.5-sonnet'),\n",
        "            ('GPT-4', 'openai/gpt-4'),\n",
        "            ('GPT-4 Turbo', 'openai/gpt-4-turbo'),\n",
        "            ('GPT-4o', 'openai/gpt-4o')\n",
        "        ],\n",
        "        value='openai/gpt-4o-mini',\n",
        "        description='Model:',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    filename_input = widgets.Text(\n",
        "        placeholder='Enter report filename (without extension)',\n",
        "        description='Report Name:',\n",
        "        value='analytics_report',\n",
        "        style={'description_width': 'initial'}\n",
        "    )\n",
        "\n",
        "    run_button = widgets.Button(\n",
        "        description='Run Multi-Agent Analysis',\n",
        "        button_style='success',\n",
        "        layout=widgets.Layout(width='300px', height='50px')\n",
        "    )\n",
        "\n",
        "    progress_bar = widgets.IntProgress(\n",
        "        value=0,\n",
        "        min=0,\n",
        "        max=7,\n",
        "        description='Progress:',\n",
        "        bar_style='info',\n",
        "        orientation='horizontal'\n",
        "    )\n",
        "\n",
        "    output_area = widgets.Output()\n",
        "\n",
        "    def on_run_clicked(b):\n",
        "        with output_area:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            if not upload_widget.value:\n",
        "                print(\"Please upload CSV files first\")\n",
        "                return\n",
        "\n",
        "            if not api_key_input.value:\n",
        "                print(\"Please enter OpenRouter API key\")\n",
        "                return\n",
        "\n",
        "            if not brave_key_input.value:\n",
        "                print(\"Please enter Brave Search API key\")\n",
        "                return\n",
        "\n",
        "            if not filename_input.value.strip():\n",
        "                print(\"Please enter a report filename\")\n",
        "                return\n",
        "\n",
        "            csv_files = {}\n",
        "            for filename, content in upload_widget.value.items():\n",
        "                csv_files[filename] = content['content'].decode('utf-8')\n",
        "\n",
        "            orchestrator = MultiAgentOrchestrator(\n",
        "                api_key_input.value,\n",
        "                brave_key_input.value,\n",
        "                model_dropdown.value\n",
        "            )\n",
        "\n",
        "            if not orchestrator.load_csv_data(csv_files):\n",
        "                return\n",
        "\n",
        "            progress_bar.value = 0\n",
        "\n",
        "            result = orchestrator.execute_workflow()\n",
        "\n",
        "            progress_bar.value = 7\n",
        "\n",
        "            pdf_filename = f\"{filename_input.value.strip()}.pdf\"\n",
        "            pdf_generator = PDFReportGenerator()\n",
        "\n",
        "            try:\n",
        "                pdf_generator.generate_pdf_report(result, pdf_filename)\n",
        "                print(f\"\\nAnalysis completed! PDF report saved as: {pdf_filename}\")\n",
        "\n",
        "                print(f\"\\nAnalysis Summary:\")\n",
        "                print(f\"- Status: {result['status']}\")\n",
        "                print(f\"- Steps completed: {result['current_step']}/7\")\n",
        "                print(f\"- Datasets analyzed: {len(result['csv_data'])}\")\n",
        "                print(f\"- Agents executed: {len(result['agent_outputs'])}\")\n",
        "\n",
        "                if 'saved_figures' in result and result['saved_figures']:\n",
        "                    fig_count = len(result['saved_figures'])\n",
        "                    print(f\"- Visualizations generated: {fig_count}\")\n",
        "                    print(f\"- Saved figures: {', '.join(result['saved_figures'])}\")\n",
        "\n",
        "                if 'successful_iteration' in result and result['successful_iteration']:\n",
        "                    print(f\"- Code approved after iteration: {result['successful_iteration']}\")\n",
        "                    print(f\"- Final code approved: {result.get('final_code_approved', False)}\")\n",
        "                    print(f\"- Analysis successful: {result.get('analysis_successful', False)}\")\n",
        "\n",
        "                if result['status'] == 'completed':\n",
        "                    print(\"Full analysis completed successfully!\")\n",
        "                    print(\"Visualizations have been included in the PDF report\")\n",
        "                    print(\"Business insights have been translated for non-technical stakeholders\")\n",
        "                    print(\"Report contains only business-friendly content\")\n",
        "                else:\n",
        "                    print(\"Analysis completed with some issues - check the PDF for details\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"PDF generation failed: {str(e)}\")\n",
        "                print(\"Generating text summary instead...\")\n",
        "\n",
        "                print(f\"\\nAnalysis Results Summary:\")\n",
        "                for agent_name, output in result['agent_outputs'].items():\n",
        "                    if not agent_name.startswith('reviewer_feedback'):\n",
        "                        print(f\"\\n{agent_name.replace('_', ' ').title()}:\")\n",
        "                        print(output[:500] + \"...\" if len(output) > 500 else output)\n",
        "\n",
        "    run_button.on_click(on_run_clicked)\n",
        "\n",
        "    ui = widgets.VBox([\n",
        "        widgets.HTML(\"<h2>Multi-Agent Analytics System</h2>\"),\n",
        "        api_key_input,\n",
        "        brave_key_input,\n",
        "        model_dropdown,\n",
        "        filename_input,\n",
        "        upload_widget,\n",
        "        run_button,\n",
        "        progress_bar,\n",
        "        output_area\n",
        "    ])\n",
        "\n",
        "    return ui\n",
        "\n",
        "# Cell 10: Main execution - create and display the interface\n",
        "ui = create_file_upload_ui()\n",
        "display(ui)\n",
        "\n",
        "print(\"\\nMulti-Agent Analytics System Ready!\")\n",
        "print(\"\\nInstructions:\")\n",
        "print(\"1. Enter your OpenRouter API key\")\n",
        "print(\"2. Enter your Brave Search API key\")\n",
        "print(\"3. Select your preferred model\")\n",
        "print(\"4. Enter a filename for your report\")\n",
        "print(\"5. Upload one or more CSV files\")\n",
        "print(\"6. Click 'Run Multi-Agent Analysis'\")\n",
        "print(\"\\nThe system will autonomously:\")\n",
        "print(\"- Analyze your data\")\n",
        "print(\"- Research market context\")\n",
        "print(\"- Plan comprehensive analysis\")\n",
        "print(\"- Generate and refine code\")\n",
        "print(\"- Execute statistical analysis\")\n",
        "print(\"- Translate technical results into business insights\")\n",
        "print(\"- Compile professional PDF report\")"
      ],
      "metadata": {
        "id": "J2PmtXddHnen"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}